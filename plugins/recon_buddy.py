import asyncio
import ipaddress
import json
import logging as logger
import os
import re
import shlex
import shutil
import socket
import subprocess
import tempfile
from concurrent.futures import ThreadPoolExecutor
from ftplib import FTP
from pathlib import Path
from tempfile import mkdtemp
from urllib.parse import parse_qs, unquote, urlencode, urljoin, urlparse, urlunparse
from urllib.request import urlretrieve
from uuid import uuid4

import nmap
from certipy.commands.find import Find
from certipy.lib.target import Target
from colorama import Fore
from humanize import naturalsize
from impacket.dcerpc.v5 import lsad, lsat, transport
from impacket.dcerpc.v5.dtypes import MAXIMUM_ALLOWED
from impacket.dcerpc.v5.rpcrt import DCERPCException
from impacket.dcerpc.v5.samr import SID_NAME_USE
from impacket.smbconnection import SessionError, SMBConnection
from ldap3 import ALL, SIMPLE, SUBTREE, Connection, Server
from python_hosts import Hosts, HostsEntry
from tornado import gen, httpclient, ioloop
from tqdm import tqdm
from xxhash import xxh64_intdigest

from pssutil.cmdutils import CmdLenValidator
from pssutil.common import get_http_status_code_color
from pssutil.fileutils import execute_and_read_file_lines

TAG = f"[{Fore.LIGHTYELLOW_EX}ReconBuddy{Fore.RESET}]"

WHATWEB_PLUGIN_BLACKLIST = ["Country", "IP"]

WORDLISTS_FOLDER = Path("./wordlists")
WORDLISTS = {
    "vhosts": "https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/DNS/subdomains-top1million-5000.txt",
    "lfi": "https://raw.githubusercontent.com/carlospolop/Auto_Wordlists/main/wordlists/file_inclusion_linux.txt",
    "lfi_windows": "https://raw.githubusercontent.com/carlospolop/Auto_Wordlists/main/wordlists/file_inclusion_windows.txt",
}

HOSTNAME_REGEX = re.compile(r"^(([a-zA-Z0-9]|[a-zA-Z0-9][a-zA-Z0-9\-]*[a-zA-Z0-9])\.)*([A-Za-z0-9]|[A-Za-z0-9][A-Za-z0-9\-]*[A-Za-z0-9])$")

IDISC_REGEXES = [
    re.compile(
        r"(.*\.(ai|asc|asp|aspx|awk|bat|c|cgi|class|cpp|cs|css|csv|dart|db|dbf|der|dll|doc|docx|ejs|elf|eps|erb|exe|gdb|gif|go|gpg|gz|h|hpp|htm|html|ini|ipynb|jar|java|jsp|js|json|jsx|key|kdbx|log|lua|mdb|md|mdb|mp3|mp4|msg|nef|o|odp|ods|odt|ogg|orf|ova|ovf|p12|pas|pb|pdf|pem|php|pl|png|ppt|pptx|ps1|psd|py|rb|reg|rpm|rs|rtf|sdf|sh|sln|sql|sqlitedb|sr2|svg|swift|tar|tif|tiff|ts|tsv|txt|vbs|vdi|vhd|vmem|vmsd|vmsn|vmss|vmtm|yml|xml).*)"
    ),
]

BANNER_REGEXES = {
    "HTTP": [
        re.compile(r"^HTTP\/.+\ [0-9]{1,3}\ "),
    ],
    "SSH": [
        re.compile(r"^SSH-[0-9]\.[0-9]-.+"),
    ],
}

FOUND_CREDENTIALS = {}


def add_cmd(pm, cmd):
    rbuddy_handler = cmd.add(["rbuddy", "reconbuddy"])
    rbuddy_handler.add(["scan"], CmdLenValidator(init_recon_scan, 1, ["hostname or ipadress"]))
    rbuddy_handler.add(["vhosts"], CmdLenValidator(init_http_vhost_scan, 1, ["hostname or ipadress"]))
    rbuddy_handler.add(["bannergrab"], CmdLenValidator(init_banner_grab, 2, ["hostname or ipadress", "port"]))
    rbuddy_handler.add(["identifyservice"], CmdLenValidator(init_service_identify, 2, ["hostname or ipadress", "port"]))
    rbuddy_handler.add(["http"], CmdLenValidator(init_http_recon_scan, 1, ["hostname or ipadress"]))
    rbuddy_handler.add(["adcs"], CmdLenValidator(init_adcs_recon_scan, 1, ["hostname or ipadress"]))
    rbuddy_handler.add(["ftp"], CmdLenValidator(init_ftp_recon_scan, 1, ["hostname or ipadress"]))
    rbuddy_handler.add(["ldap"], CmdLenValidator(init_ldap_recon_scan, 1, ["hostname or ipadress"]))
    rbuddy_handler.add(["snmp"], CmdLenValidator(init_snmp_recon_scan, 1, ["hostname or ipadress"]))
    rbuddy_handler.add(["smb"], CmdLenValidator(init_smb_recon_scan, 1, ["hostname or ipadress"]))
    rbuddy_handler.add(["rid_bruteforce"], CmdLenValidator(init_rid_bruteforce, 1, ["hostname or ipadress"]))
    rbuddy_handler.add(["nfs"], CmdLenValidator(init_nfs_recon_scan, 1, ["hostname or ipadress"]))

    wordlists_handler = rbuddy_handler.add(["wordlists"])
    wordlists_handler.add(["update"], update_wordlists)

    credentials_handler = rbuddy_handler.add(["credentials"])
    credentials_handler.add(["add"], CmdLenValidator(add_credentials, 3, ["type", "username", "password"]))
    credentials_handler.add(["show"], show_credentials)
    credentials_handler.add(["clear"], clear_credentials)

    lfi_handler = rbuddy_handler.add(["lfi"])
    lfi_handler.add(["scan"], CmdLenValidator(init_http_lfi_scan, 1, ["url with parameters"]))


def update_wordlists(args):
    for filename, url in WORDLISTS.items():
        download_wordlist(url, Path(WORDLISTS_FOLDER, filename))


def add_credentials(args):
    add_global_credentials(args[0], args[1], args[2])


def show_credentials(args):
    global FOUND_CREDENTIALS

    for credential_type, creds in FOUND_CREDENTIALS.items():
        print(f"{Fore.LIGHTYELLOW_EX}{credential_type}{Fore.RESET}")

        for username, password in creds.items():
            print(
                f" - {Fore.LIGHTGREEN_EX if password else ''}{username}{Fore.RESET}:{Fore.LIGHTGREEN_EX if password else ''}{password}{Fore.RESET}"
            )


def clear_credentials(args):
    global FOUND_CREDENTIALS
    FOUND_CREDENTIALS.clear()


def download_wordlist(url, path):
    try:
        if not WORDLISTS_FOLDER.exists():
            os.makedirs(WORDLISTS_FOLDER)

        logger.info(f'{TAG} Downloading "{Fore.LIGHTCYAN_EX}{path}{Fore.RESET}": {Fore.LIGHTCYAN_EX}{url}{Fore.RESET}')

        if path.exists():
            os.remove(path)

        urlretrieve(url, path)
    except Exception as ex:
        logger.error(f'{TAG} Failed to download wordlist "{Fore.LIGHTCYAN_EX}{path}{Fore.RESET}": {ex}')


def get_wordlist(name):
    try:
        if name in WORDLISTS:
            path = Path(WORDLISTS_FOLDER, name)

            if not path.exists():
                download_wordlist(WORDLISTS[name], path)

            with open(path) as wl:
                return [x.strip() for x in wl.readlines()]
    except Exception as ex:
        logger.error(f'{TAG} Failed to read wordlist "{Fore.LIGHTCYAN_EX}{path}{Fore.RESET}": {ex}')
    return []


def generate_wordlist_cewl(url):
    try:
        return execute_and_read_file_lines(f"cewl --convert-umlauts -w '{{FILE}}' {url}")
    except Exception as ex:
        logger.error(f'{TAG} Failed to generate wordlist with cewl for "{Fore.LIGHTCYAN_EX}{url}{Fore.RESET}": {ex}')
    return []


def generate_wordlist_cewler(url):
    try:
        return execute_and_read_file_lines(
            f"cewler --min-word-length 3 -s children --include-js --include-css --include-pdf --output '{{FILE}}' {url}"
        )
    except Exception as ex:
        logger.error(f'{TAG} Failed to generate wordlist with cewler for "{Fore.LIGHTCYAN_EX}{url}{Fore.RESET}": {ex}')
    return []


def init_recon_scan(args):
    try:
        host = args[0]
        nmap_scanner = nmap.PortScanner()

        min_rate = int(args[1]) if len(args) > 1 else 100
        services = {}

        def identified_service(services, service, port, print_msg: bool = False):
            if service not in services:
                services[service] = []

            if port not in services[service]:
                services[service].append(port)

            if print_msg:
                logger.info(f"{TAG} >> {Fore.LIGHTGREEN_EX}Service identified as{Fore.RESET}: {Fore.YELLOW}{service}{Fore.RESET}")

        logger.info(f"{TAG} Scanning TCP: {host}")
        nmap_tcp_scan = nmap_scanner.scan(host, arguments=f"-Pn -O -sV --min-rate {min(6000, min_rate)} -p-")

        if "scan" in nmap_tcp_scan and host in nmap_tcp_scan["scan"]:
            if "tcp" in nmap_tcp_scan["scan"][host] and nmap_tcp_scan["scan"][host]["tcp"]:
                for port, data in nmap_tcp_scan["scan"][host]["tcp"].items():
                    service_name = f'{data.get("product", "n/a")} {data.get("version", "n/a")}'.strip()
                    logger.info(
                        f'{TAG} TCP {Fore.LIGHTCYAN_EX}{str(port).ljust(5)}{Fore.RESET} : {data.get("state", "unknown")} [{Fore.YELLOW}{data.get("name", "NONE").upper()}{Fore.RESET}] ({Fore.YELLOW}{service_name}{Fore.RESET})'
                    )

                    if "name" in data and data["name"] and data["name"].lower() != "unknown":
                        if "version" in data and data["version"]:
                            run_exploitdb_lookup(service_name)

                        identified_service(services, data["name"], port)
                    else:
                        service = try_identify_service_tcp(host, port)

                        if service:
                            identified_service(services, service, port, True)
            else:
                logger.warn(f"{TAG} No open TCP ports found...")
        else:
            logger.error(f"{TAG} Failed to run nmap TCP scan...")

        logger.info(f"{TAG} Scanning UDP: {host}")
        nmap_udp_scan = nmap_scanner.scan(host, arguments=f"-Pn -sU --min-rate {min(2000, min_rate)}")

        if "scan" in nmap_udp_scan and host in nmap_udp_scan["scan"]:
            if "udp" in nmap_udp_scan["scan"][host] and nmap_udp_scan["scan"][host]["udp"]:
                for port, data in nmap_udp_scan["scan"][host]["udp"].items():
                    if data.get("state", "unknown") != "closed":
                        service_name = f'{data.get("product", "n/a")} {data.get("version", "n/a")}'
                        logger.info(
                            f'{TAG} UDP {Fore.LIGHTCYAN_EX}{str(port).ljust(5)}{Fore.RESET} : {data.get("state", "unknown")} [{Fore.YELLOW}{data.get("name", "NONE").upper()}{Fore.RESET}] ({Fore.YELLOW}{service_name}{Fore.RESET})'
                        )

                        if "name" in data and data["name"] and data["name"].lower() != "unknown":
                            if "version" in data and data["version"]:
                                run_exploitdb_lookup(service_name)

                            identified_service(services, data["name"], port)
                        else:
                            service = try_identify_service_udp(host, port)

                            if service:
                                identified_service(services, service, port, True)
            else:
                logger.warn(f"{TAG} No open UDP ports found...")
        else:
            logger.error(f"{TAG} Failed to run nmap UDP scan...")

        for service, ports in services.items():
            service = service.upper()

            if service == "HTTP":
                [http_recon(host, port) for port in ports]
            elif service == "SNMP":
                [snmp_recon(host, port) for port in ports]
            elif service == "MICROSOFT-DS":
                [init_rid_bruteforce([host, port]) for port in ports]
                [smb_recon(host, port) for port in ports]
            elif service == "LDAP":
                [ldap_recon(host, port) for port in ports]
            elif service == "FTP":
                [ftp_recon(host, port) for port in ports]
            elif service == "NFS" or service == "NFS_ACL":
                [nfs_recon(host, port) for port in ports]
            elif service == "MSRPC":
                pass

    except Exception as ex:
        logger.error(f"{TAG} Failed to run recon scan: {ex}")


def init_http_recon_scan(args):
    try:
        if len(args) > 1:
            http_recon(args[0], int(args[1]))
        else:
            is_https = args[0].startswith("https:")
            http_recon(args[0], 443 if is_https else 80, is_https)
    except Exception as ex:
        logger.error(f"{TAG} Failed to run HTTP recon: {ex}")


def init_adcs_recon_scan(args):
    try:
        adcs_recon(args[0], args[1], args[2], args[3])
    except Exception as ex:
        logger.error(f"{TAG} Failed to run AD-CS recon: {ex}")


def init_ftp_recon_scan(args):
    try:
        ftp_recon(
            args[0],
            int(args[1]) if len(args) > 1 else 21,
            int(args[2]) if len(args) > 2 else 2,
            False,
            args[3] if len(args) > 3 else None,
            args[4] if len(args) > 4 else None,
        )
    except Exception as ex:
        logger.error(f"{TAG} Failed to run FTP recon: {ex}")


def init_ldap_recon_scan(args):
    try:
        ldap_recon(
            args[0],
            int(args[1]) if len(args) > 1 else 389,
            domain=args[2] if len(args) > 2 else None,
            user=args[3] if len(args) > 3 else None,
            password=args[4] if len(args) > 4 else None,
        )
    except Exception as ex:
        logger.error(f"{TAG} Failed to run LDAP recon: {ex}")


def init_snmp_recon_scan(args):
    try:
        snmp_recon(args[0], int(args[1]) if len(args) > 1 else 161)
    except Exception as ex:
        logger.error(f"{TAG} Failed to run SNMP recon: {ex}")


def init_smb_recon_scan(args):
    try:
        smb_recon(
            args[0],
            int(args[1]) if len(args) > 1 else 445,
            int(args[2]) if len(args) > 2 else 2,
            False,
            args[3] if len(args) > 3 else "guest",
            args[4] if len(args) > 4 else "",
        )
    except Exception as ex:
        logger.error(f"{TAG} Failed to run SMB recon: {ex}")


def init_rid_bruteforce(args):
    try:
        port = int(args[1]) if len(args) > 1 else 445

        entries = rid_bruteforce(
            args[0],
            port,
            args[2] if len(args) > 2 else "guest",
            args[3] if len(args) > 3 else "",
            int(args[4]) if len(args) > 4 else 10000,
        )

        last_sid_type = None
        entries.sort(key=lambda x: x["sidtype"])

        for user in entries:
            if user["sidtype"] != last_sid_type:
                last_sid_type = user["sidtype"]
                logger.info(f"{TAG} {last_sid_type}")

            print(f"{user['rid']:6}: {user['domain']}\\{user['username']}")

            if user["sidtype"] == "SidTypeUser":
                add_global_credentials("windows", user["username"])
                init_smb_bruteforce(args[0], port, user["username"])

        return entries
    except Exception as ex:
        logger.error(f"{TAG} Failed to run RID brutforce: {ex}")


def init_smb_bruteforce(host, port, username):
    # try username and username without $ and lowercase (pre created accounts)
    for pw in [username, username.replace("$", "").lower()]:
        try:
            conn = SMBConnection(host, host, None, port, 3)
            conn.login(username, pw)
            print(f"        -> {Fore.LIGHTGREEN_EX}STATUS_SUCCESS{Fore.RESET}: {pw}")
            add_global_credentials("windows", username, pw)
            break
        except SessionError as smbex:
            smb_msg = smbex.getErrorString()[0]

            if smb_msg != "STATUS_LOGON_FAILURE":
                print(f"        -> {Fore.LIGHTYELLOW_EX}{smb_msg}{Fore.RESET}: {pw}")
                add_global_credentials("windows", username, pw)


def add_global_credentials(credential_type, username, password=None):
    global FOUND_CREDENTIALS
    if credential_type not in FOUND_CREDENTIALS:
        FOUND_CREDENTIALS[credential_type] = {}
    FOUND_CREDENTIALS[credential_type][username] = password


def get_global_credentials(credential_type):
    global FOUND_CREDENTIALS
    if credential_type in FOUND_CREDENTIALS:
        return FOUND_CREDENTIALS[credential_type]
    return None


def init_nfs_recon_scan(args):
    try:
        nfs_recon(
            args[0],
            int(args[1]) if len(args) > 1 else 2049,
            int(args[2]) if len(args) > 2 else 2,
            False,
            args[3] if len(args) > 3 else "guest",
            args[4] if len(args) > 4 else "",
        )
    except Exception as ex:
        logger.error(f"{TAG} Failed to run NFS recon: {ex}")


def init_banner_grab(args):
    try:
        identify_by_banner_grabbing(args[0], int(args[1]), True)
    except Exception as ex:
        logger.error(f"{TAG} Failed to run banner grab: {ex}")


def init_service_identify(args):
    try:
        service = try_identify_service_tcp(args[0], int(args[1]))

        if service:
            logger.info(f"{TAG} >> {Fore.LIGHTGREEN_EX}Service identified as{Fore.RESET}: {Fore.YELLOW}{service}{Fore.RESET}")
        else:
            logger.info(f"{TAG} >> {Fore.LIGHTRED_EX}Service could not be identified{Fore.RESET}")
    except Exception as ex:
        logger.error(f"{TAG} Failed to identify service: {ex}")


def try_identify_service_tcp(host: str, port: int, print_banner: bool = False):
    try:
        service = identify_by_banner_grabbing(host, port, print_banner)

        if service:
            return service
        else:
            indentifiers = {"HTTP": [indentify_http_service]}

            for service, identifier_fns in indentifiers.items():
                for identifier_fn in identifier_fns:
                    if identifier_fn(host, port):
                        return service
    except Exception as ex:
        logger.error(f"{TAG} Failed to identify service: {ex}")

    return None


def try_identify_service_udp(host: str, port: int, print_banner: bool = False):
    try:
        pass
    except Exception as ex:
        logger.error(f"{TAG} Failed to identify service: {ex}")

    return None


def build_url(scheme, host, port):
    url = f"{host}"

    if port != 80 and port != 443 and ":" not in url:
        url = f"{url}:port"

    if not url.startswith("http"):
        url = f"{scheme}://{url}"

    return url


def run_cmd(cmd):
    return subprocess.run(shlex.split(cmd), capture_output=True).stdout


def run_exploitdb_lookup(service_name):
    if service_name.startswith(" "):
        return

    try:
        searchsploit_result = json.loads(run_cmd(f"searchsploit -w --json '{service_name}'"))

        if "RESULTS_EXPLOIT" in searchsploit_result and searchsploit_result["RESULTS_EXPLOIT"]:
            result_str = f"{Fore.RESET}\n".join(
                [f"{Fore.LIGHTYELLOW_EX}{x['Title']}{Fore.RESET}: {x['URL']}" for x in searchsploit_result["RESULTS_EXPLOIT"]]
            )
            result_str = re.sub("- ", f"{Fore.RESET} - {Fore.LIGHTRED_EX}", result_str)
            logger.info(f"{TAG} >> {Fore.LIGHTGREEN_EX}Exploits available{Fore.RESET}:\n{result_str}")
        else:
            # logger.info(f"{TAG} >> {Fore.WHITE}No exploits found...{Fore.RESET}")
            pass
    except Exception as ex:
        logger.error(f"{TAG} Failed to search for exploits: {ex}")


def run_whatweb(url):
    _, path = tempfile.mkstemp(suffix=".json")

    try:
        run_cmd(f"whatweb -q --log-json '{path}' '{url}'")

        with open(path) as tmp_file:
            whatweb_results = json.loads(tmp_file.read())

            for whatweb_result in whatweb_results:
                if "target" in whatweb_result and "plugins" in whatweb_result:
                    whatweb_plugin_results = []

                    for x, y in whatweb_result["plugins"].items():
                        if x not in WHATWEB_PLUGIN_BLACKLIST and y:
                            whatweb_plugin_results.append(f"{Fore.LIGHTYELLOW_EX}{x}{Fore.RESET}: {y}")

                    result_str = "\n".join(whatweb_plugin_results)
                    logger.info(f"{TAG} >> whatweb results for \"{whatweb_result['target']}\":\n{result_str}")
    finally:
        os.remove(path)


def add_host_entry(hosts, ip, hostname):
    entry_type = "ipv4" if isinstance(ip, ipaddress.IPv4Address) else "ipv6"
    existing_hosts = hosts.find_all_matching(address=str(ip))

    if len(existing_hosts) > 0:
        for entry in existing_hosts:
            if hostname in entry.names:
                return

    hosts.add([HostsEntry(entry_type=entry_type, address=str(ip), names=[hostname])], merge_names=True)
    hosts.write()
    logger.info(f'{TAG} Created hostentry: "{Fore.YELLOW}{hostname}{Fore.RESET}" -> "{Fore.YELLOW}{ip}{Fore.RESET}"')


def http_handle_unknown_host(url, redirect):
    try:
        parsed_url = urlparse(url)

        if HOSTNAME_REGEX.match(redirect):
            scheme = parsed_url.scheme or "http"
            redirect = f"{scheme}://{redirect}"

        parsed_redirect = urlparse(redirect)

        if parsed_url.hostname == parsed_redirect.hostname:
            # only http changed to https or location changed, not relevant for us
            return

        # check wheter a host can be resolved, if not, add it to the hosts file
        try:
            socket.getaddrinfo(parsed_redirect.hostname)
            # we can resolve it, no need to add host entry
            return
        except:
            hosts = Hosts()

            try:
                # url is a ip
                ip = ipaddress.ip_address(parsed_url.hostname)
                add_host_entry(hosts, ip, parsed_redirect.hostname)
                return
            except:
                # url seems to be a hostname, try to resolve the ip and add it to the hosts file
                for host_entry in hosts.find_all_matching(name=parsed_url.hostname):
                    try:
                        add_host_entry(hosts, ipaddress.ip_address(host_entry.address), parsed_redirect.hostname)
                        return
                    except:
                        pass

                logger.error(f"{TAG} Failed to auto create hostentry")

    except:
        pass


def http_follow_redirects(url) -> str:
    resp = None

    try:
        resp = httpclient.HTTPClient().fetch(url, follow_redirects=False, validate_cert=False, raise_error=False)

        # only hanlde permanent redirects
        if resp.code in [301, 302, 307, 308]:
            redirect_loc = resp.headers.get("Location", None) or resp.headers.get("location", None)

            if redirect_loc:
                if not redirect_loc.startswith("http"):
                    redirect_loc = urljoin(url, redirect_loc)

                logger.info(f'{TAG} Redirect detected: "{Fore.YELLOW}{url}{Fore.RESET}" -> "{Fore.YELLOW}{redirect_loc}{Fore.RESET}"')
                http_handle_unknown_host(url, redirect_loc)
                url = http_follow_redirects(redirect_loc)
    except Exception as ex:
        logger.error(f"{TAG} Failed to follow redirect: {ex}")

    return url


def http_send_get(urls, description):
    http_client = httpclient.AsyncHTTPClient()
    reqs = [
        http_client.fetch(
            url,
            method="GET",
            request_timeout=0,
            validate_cert=False,
            raise_error=False,
            follow_redirects=False,
        )
        for url in urls
    ]
    return http_send_requests(reqs, description)


def http_send_requests(reqs, description):
    @gen.coroutine
    def fetch_and_handle():
        results = []
        waiter = gen.WaitIterator(*reqs)

        with tqdm(
            ascii=True,
            desc=description,
            unit=f" {Fore.YELLOW}requests{Fore.RESET}",
            total=len(reqs),
        ) as pbar:
            while not waiter.done():
                try:
                    response = yield waiter.next()
                except:
                    pass
                else:
                    results.append(response)

                pbar.update()

        return results

    return ioloop.IOLoop.current().run_sync(fetch_and_handle)


def http_discover_hvosts(url, wordlist):
    target = urlparse(url)

    rngstr = abs(hash(uuid4().hex)) % (10**16)
    rngurl = f"{rngstr}.{target.hostname}"
    logger.info(f'{TAG} Using random url as hopefully non-existing sample "{Fore.YELLOW}{rngurl}{Fore.RESET}"')

    initial_response = httpclient.HTTPClient().fetch(
        url, headers={"Host": rngurl}, method="GET", follow_redirects=False, validate_cert=False, raise_error=False
    )
    initial_response_hash = xxh64_intdigest(initial_response.body)

    http_client = httpclient.AsyncHTTPClient()
    reqs = [
        http_client.fetch(
            url,
            method="GET",
            headers={"Host": f"{u}.{target.hostname}"},
            request_timeout=0,
            connect_timeout=0,
            validate_cert=False,
            raise_error=False,
            follow_redirects=False,
        )
        for u in wordlist
    ]

    possible_vhosts = http_send_requests(reqs, f"{Fore.YELLOW}Scanning vHosts{Fore.RESET}")
    valid_status_codes = list(range(200, 299)) + [301, 302, 307, 401, 403, 405, 500]

    def filter_respone(response):
        try:
            if response.code in valid_status_codes and xxh64_intdigest(response.body) != initial_response_hash:
                return (response.request.headers.get("Host", None) or response.request.headers.get("host", None), response.code)
        except:
            pass
        return (None, 0)

    vhosts = {}

    with ThreadPoolExecutor() as pool:
        for vs in pool.map(filter_respone, possible_vhosts):
            if vs[0]:
                vhosts[vs[0]] = vs[1]

    return vhosts


def http_recon(host, port, https: bool = False):
    try:
        url = build_url("https" if https else "http", host, port)
        url = http_follow_redirects(url)
        parsed_url = urlparse(url)

        try:
            run_whatweb(url)
        except Exception as ex_whatweb:
            logger.error(f"{TAG} Failed to run whatweb: {ex_whatweb}")

        try:
            ipaddress.ip_address(parsed_url.hostname)
        except:
            # scan vhosts if url is a hostname
            vhosts = init_http_vhost_scan([url])

            if vhosts:
                for vhost, status_code in vhosts:
                    http_handle_unknown_host(url, vhost)
                    http_recon(vhost, port)
    except Exception as ex:
        logger.error(f"{TAG} Failed to run HTTP recon: {ex}")


def adcs_recon(host, domain, user, password):
    target = Target.create(target_ip=host, dc_ip=host, domain=domain, username=user, password=password)
    find = Find(target, vulnerable=True, stdout=True)
    find.find()


def snmp_recon(host, port):
    try:
        if shutil.which("snmpbulkwalk"):
            logger.info(f"{TAG} Walking SNMP using snmpbulkwalk...")
            snmp_lines = execute_and_read_file_lines(f"snmpbulkwalk {host} -v 2c -c public > {{FILE}}", True)

            for regex in IDISC_REGEXES:
                for match in regex.findall(snmp_lines):
                    print(match[0])
        else:
            logger.warn(f"{TAG} Unable to walk SNMP: snmpbulkwalk not installed...")
    except Exception as ex:
        logger.error(f"{TAG} Failed to run SNMP recon: {ex}")


def smb_recon(host, port, max_depth=2, silent=False, user=None, password=None):
    global FOUND_CREDENTIALS

    try:
        logger.info(f"{TAG} Running SMB recon:")
        conn = SMBConnection(host, host, None, port, 5)
        found_creds = False

        if user and password:
            found_creds = True
            conn.login(user, password)
        else:
            creds = get_global_credentials("windows")
            if creds:
                for username, password in creds.items():
                    if username and password:
                        try:
                            conn.login(username, password)
                            logger.info(
                                f"{TAG} -> Using credentials {Fore.LIGHTGREEN_EX}{username}{Fore.RESET}:{Fore.GREEN}{password}{Fore.RESET}"
                            )
                            found_creds = True
                            break
                        except:
                            pass

        if not found_creds:
            conn.login("guest", "")

        for share in sorted(conn.listShares(), key=lambda x: x["shi1_type"], reverse=True):
            share_name = share["shi1_netname"][:-1]
            share_type = share["shi1_type"]
            print(f"[{share_type:10}] {Fore.LIGHTYELLOW_EX}{share_name}{Fore.RESET} \"{share['shi1_remark'][:-1]}\"", end="")

            if share_type == 0:
                try:

                    def list_share(sname, path, print_status=False, max_depth=2, depth=0):
                        if depth < max_depth:
                            try:
                                files = conn.listPath(sname, f"{path}*")

                                if print_status:
                                    print(f": {Fore.LIGHTGREEN_EX}STATUS_SUCCESS{Fore.RESET}")

                                for file_info in files:
                                    filename = file_info.get_longname()

                                    if filename not in [".", ".."]:
                                        if file_info.is_directory():
                                            appendix = f"{Fore.WHITE}/{Fore.RESET}"
                                        else:
                                            appendix = f" ({naturalsize(file_info.get_filesize())})"

                                        for regex in IDISC_REGEXES:
                                            if regex.match(filename):
                                                file_color = Fore.LIGHTGREEN_EX
                                                break
                                        else:
                                            file_color = Fore.WHITE

                                        print(f"{depth * '  '}{file_color}{filename}{Fore.RESET}{appendix}")

                                        if file_info.is_directory():
                                            list_share(share_name, f"{path}{file_info.get_longname()}/", False, max_depth, depth + 1)
                            except SessionError as se:
                                print(f"{Fore.LIGHTRED_EX}{se.getErrorString()[0]}{Fore.RESET}")

                    tree_id = conn.connectTree(share_name)
                    list_share(share_name, "", True, max_depth)
                    conn.disconnectTree(tree_id)
                except SessionError as se:
                    print(f": {Fore.LIGHTRED_EX}{se.getErrorString()[0]}{Fore.RESET}")
            else:
                print()

    except SessionError as se:
        logger.error(f"{TAG} Failed to run SMB recon: {Fore.LIGHTRED_EX}{se.getErrorString()[0]}{Fore.RESET}")
    except Exception as ex:
        if not silent:
            logger.error(f"{TAG} Failed to run SMB recon: {ex}")


def rid_bruteforce(host, port, user="guest", password="", max_rid=10000):
    entries = []
    KNOWN_PROTOCOLS = {
        135: {"bindstr": r"ncacn_ip_tcp:%s", "set_host": False},
        139: {"bindstr": r"ncacn_np:{}[\pipe\lsarpc]", "set_host": True},
        445: {"bindstr": r"ncacn_np:{}[\pipe\lsarpc]", "set_host": True},
    }

    try:
        logger.info(f"{TAG} Bruteforcing RID's:")
        string_binding = KNOWN_PROTOCOLS[port]["bindstr"]
        rpc_transport = transport.DCERPCTransportFactory(string_binding)
        rpc_transport.set_dport(port)

        if KNOWN_PROTOCOLS[port]["set_host"]:
            rpc_transport.setRemoteHost(host)

        if hasattr(rpc_transport, "set_credentials"):
            rpc_transport.set_credentials(user, password, "", "", "", "")  # self.domain, self.lmhash, self.nthash, self.aesKey

        dce = rpc_transport.get_dce_rpc()
        dce.connect()
    except Exception as ex:
        logger.error(f"{TAG} Failed to create DCERPC connection: {Fore.LIGHTRED_EX}{ex.getErrorString()[0]}{Fore.RESET}")
        return entries

    dce.bind(lsat.MSRPC_UUID_LSAT)

    try:
        resp = lsad.hLsarOpenPolicy2(dce, MAXIMUM_ALLOWED | lsat.POLICY_LOOKUP_NAMES)
    except lsad.DCERPCSessionError as ex:
        logger.error(f"{TAG} Error while connecting: {ex}")
        return entries

    policy_handle = resp["PolicyHandle"]

    resp = lsad.hLsarQueryInformationPolicy2(
        dce,
        policy_handle,
        lsad.POLICY_INFORMATION_CLASS.PolicyAccountDomainInformation,
    )

    domain_sid = resp["PolicyInformation"]["PolicyAccountDomainInfo"]["DomainSid"].formatCanonical()

    so_far = 0
    simultaneous = 1000

    for _ in range(max_rid // simultaneous + 1):
        sids_to_check = (max_rid - so_far) % simultaneous if (max_rid - so_far) // simultaneous == 0 else simultaneous

        if sids_to_check == 0:
            break

        sids = [f"{domain_sid}-{i:d}" for i in range(so_far, so_far + sids_to_check)]

        try:
            lsat.hLsarLookupSids(dce, policy_handle, sids, lsat.LSAP_LOOKUP_LEVEL.LsapLookupWksta)
        except DCERPCException as e:
            if str(e).find("STATUS_NONE_MAPPED") >= 0:
                so_far += simultaneous
                continue
            elif str(e).find("STATUS_SOME_NOT_MAPPED") >= 0:
                resp = e.get_packet()
            else:
                raise

        for n, item in enumerate(resp["TranslatedNames"]["Names"]):
            if item["Use"] != SID_NAME_USE.SidTypeUnknown:
                rid = so_far + n
                domain = resp["ReferencedDomains"]["Domains"][item["DomainIndex"]]["Name"]
                user = item["Name"]
                sid_type = SID_NAME_USE.enumItems(item["Use"]).name
                entries.append(
                    {
                        "rid": rid,
                        "domain": domain,
                        "username": user,
                        "sidtype": sid_type,
                    }
                )
        so_far += simultaneous

    dce.disconnect()
    return entries


def nfs_recon(host, port, max_depth=2, silent=False, user="guest", password=""):
    try:
        logger.info(f"{TAG} Running NFS recon:")

        output = subprocess.check_output(["showmount", "--exports", host])
        shares = [line.split()[0] for line in output.decode().splitlines()[1:]]
        logger.info(f"{TAG} Available NFS Shares: {shares}")

        for share in shares:
            try:
                tmp_mnt = mkdtemp()
                ret_code = subprocess.run(["mount", "-t", "nfs", host + ":" + share, tmp_mnt]).returncode

                if ret_code == 0:
                    logger.info(f"{TAG} Mounted: {host + ':' + share} -> {tmp_mnt}")

                    try:
                        for root, dirs, files in os.walk(tmp_mnt):
                            for file in files:
                                print(os.path.join(root, file))
                    finally:
                        subprocess.run(["umount", tmp_mnt])
                        logger.info(f"{TAG} Unmounted: {share} -> {tmp_mnt}")
                else:
                    logger.warning(f"{TAG} Mounting failed: {host + ':' + share} -> {tmp_mnt}")

                shutil.rmtree(tmp_mnt)
            except Exception as e:
                print(f"Error mounting NFS share: {e}")

    except Exception as ex:
        if not silent:
            logger.error(f"{TAG} Failed to run NFS recon: {ex}")


def ftp_recon(host, port, max_depth=2, silent=False, user=None, password=None):
    ftp = FTP()

    try:
        ftp.connect(host, port)

        if user and password:
            ftp.login(user, password)
        else:
            ftp.login()

        logger.info(f"{TAG} Connected to FTP server: {ftp.getwelcome()}")

        def ftp_list_dir(ftp, ftp_directory, depth=0):
            try:
                ftp.cwd(ftp_directory)

                for file in ftp.nlst():
                    try:
                        ftp.cwd(file)

                        pwd = ftp.pwd()
                        print(f"{' ' * depth}{pwd}")

                        ftp_list_dir(ftp, pwd, depth + 1)
                        ftp.cwd("..")
                    except:
                        for regex in IDISC_REGEXES:
                            if regex.match(file):
                                file_color = Fore.LIGHTGREEN_EX
                                break
                        else:
                            file_color = Fore.WHITE

                        print(f"{' ' * depth}{file_color}{file}{Fore.RESET} ({naturalsize(ftp.size(file))})")
            except Exception as le:
                logger.error(f'{TAG} Failed to list "{ftp.pwd()}": {le}')

        ftp_list_dir(ftp, "/")
    except Exception as ex:
        logger.error(f"{TAG} Failed to run FTP recon: {ex}")
    finally:
        ftp.quit()


def ldap_recon(host, port, protocol="ldap", silent=False, domain=None, user=None, password=None):
    try:
        logger.info(f"{TAG} Running LDAP recon:")
        server = Server(f"{protocol}://{host}", port, get_info=ALL)
        found_creds = False

        if user and password:
            found_creds = True
            conn = Connection(server, user=user, password=password, auto_bind=True, authentication=SIMPLE)
            conn.bind()
        else:
            creds = get_global_credentials("windows")
            if creds:
                for username, password in creds.items():
                    if username and password:
                        try:
                            conn = Connection(server, user=user, password=password, auto_bind=True, authentication=SIMPLE)
                            conn.bind()
                            logger.info(
                                f"{TAG} -> Using credentials {Fore.LIGHTGREEN_EX}{username}{Fore.RESET}:{Fore.GREEN}{password}{Fore.RESET}"
                            )
                            found_creds = True
                            break
                        except:
                            pass

        if not found_creds:
            conn = Connection(server, auto_bind=True)
            conn.bind()

        try:
            base_dn = server.info.other["defaultNamingContext"][0]
        except:
            try:
                base_dn = server.info.other["rootDomainNamingContext"][0]
            except:
                try:
                    base_dn = server.info.naming_contexts[0]
                except:
                    logger.error(f"{TAG} Unable to find base DN for LDAP server...")
                    return

        conn.search(search_base=base_dn, search_filter="(objectClass=*)", search_scope=SUBTREE, attributes="*")

        possible_users = []
        interesting_descriptions = {}

        for entry in conn.entries:
            print(f"[{Fore.LIGHTYELLOW_EX}{entry.entry_dn}{Fore.RESET}]")

            if "OU=" in entry.entry_dn or ("objectClass" in entry.entry_attributes and "user" in entry["objectClass"]):
                try:
                    if "sAMAccountName" in entry.entry_attributes:
                        possible_users.append(entry["sAMAccountName"])
                    else:
                        possible_users.append(entry.entry_dn.split("CN=")[1].split(",")[0])
                except:
                    pass

            for attribute in entry.entry_attributes:
                attr = str(entry[attribute])
                color = Fore.WHITE

                if "password" in attr.lower() and "rodc password" not in attr.lower() and "rodc password" not in entry.entry_dn.lower():
                    color = Fore.LIGHTGREEN_EX

                    if entry.entry_dn not in interesting_descriptions:
                        interesting_descriptions[entry.entry_dn] = []

                    interesting_descriptions[entry.entry_dn].append(f"{attribute}: {attr}")

                print(f"{attribute}: {color}{attr}{Fore.RESET}")

            print()

        logger.info(f'{TAG} Server base DN: "{Fore.LIGHTYELLOW_EX}{base_dn}{Fore.RESET}"')

        if possible_users:
            logger.info(f"{TAG} Possible usernames:")

            for user in possible_users:
                print(str(user))

            print()

        if interesting_descriptions:
            logger.info(f"{TAG} Attributes with interesting stuff:")

            for dn, attributes in interesting_descriptions.items():
                print(f"[{Fore.LIGHTYELLOW_EX}{dn}{Fore.RESET}]")

                for attribute in attributes:
                    print(attribute)

                print()
    except Exception as ex:
        logger.error(f"{TAG} Failed to run LDAP recon: {ex}")


def init_http_vhost_scan(args):
    try:
        url = http_follow_redirects(args[0])

        if shutil.which("cewl"):
            wl_cewl = generate_wordlist_cewl(url)

        if shutil.which("cewler"):
            wl_cewler = generate_wordlist_cewler(url)

        vhosts = http_discover_hvosts(url, set(get_wordlist("vhosts") + wl_cewl + wl_cewler))
        vhosts = sorted(vhosts.items(), key=lambda x: (-x[1], x[0]))

        for vhost, status_code in vhosts:
            logger.info(
                f"{TAG} Discovered vHost: {Fore.YELLOW}{vhost}{Fore.RESET} => {get_http_status_code_color(status_code)}{status_code}{Fore.RESET}"
            )

        return vhosts
    except Exception as ex:
        logger.error(f"{TAG} Failed to run vHost scan: {ex}")


def init_http_lfi_scan(args):
    url = list(urlparse(args[0]))
    parameters = parse_qs(url[4])
    lfi_parameters = list(filter(None, [x if "LFI" in y else None for x, y in parameters.items()]))

    lfi_urls = {}
    lfi_count = 0

    for lfi in get_wordlist("lfi_windows"):
        try:
            lfi = lfi.replace("\\", "\\\\")
            filename = Path(unquote(lfi)).name

            if filename not in lfi_urls:
                lfi_urls[filename] = []

            for lfi_param in lfi_parameters:
                url_copy = url.copy()
                new_parameters = parameters.copy()
                new_parameters[lfi_param] = re.sub("LFI", lfi, new_parameters[lfi_param][0])
                url_copy[4] = urlencode(new_parameters)
                lfi_urls[filename].append(urlunparse(url_copy))
                lfi_count += 1
        except Exception as ex:
            logger.error(f'{TAG} Invalid LFI path "{lfi}": {ex}')

    lfi_responses = {}

    async def scan_url_lfi(file, urls, pbar):
        http_client = httpclient.AsyncHTTPClient()
        valid_status_codes = list(range(200, 299)) + [301, 302, 307]

        async def fetch_website(http_client, u):
            try:
                response = await http_client.fetch(u, method="GET", follow_redirects=False, validate_cert=False, raise_error=False)

                if response.code in valid_status_codes:
                    lfi_responses[u] = len(response.body)
                    return True
            except:
                return False

        for u in urls:
            if await fetch_website(http_client, u):
                break

        pbar.update()

    with tqdm(
        ascii=True,
        desc="Scanning LFI's",
        unit=f" {Fore.YELLOW}requests{Fore.RESET}",
        total=len(lfi_urls),
    ) as pbar:

        async def scan_url_lfis(futures):
            return await asyncio.gather(*futures)

        asyncio.run(scan_url_lfis([scan_url_lfi(file, urls, pbar) for file, urls in lfi_urls.items()]))

    for lfiurl, size in {k: v for k, v in sorted(lfi_responses.items(), key=lambda item: item[1])}.items():
        logger.info(f'{TAG} Possible LFI "{Fore.LIGHTGREEN_EX}{lfiurl}{Fore.RESET}": {size}')


def identify_by_banner_grabbing(host: str, port: int, print_banner: bool = False):
    try:
        sock = socket.socket()
        sock.settimeout(4)
        sock.connect((host, port))
        sock.send("\r\n\0".encode("ASCII"))
        banner_bytes = sock.recv(1024)
        sock.close()

        banner = banner_bytes.decode(errors="ignore").strip()

        if banner:
            if print_banner:
                logger.info(f"{TAG} Grabbed banner:\n{Fore.LIGHTWHITE_EX}{banner}{Fore.RESET}")

            for service, regexes in BANNER_REGEXES.items():
                for rgx in regexes:
                    if rgx.match(banner):
                        if print_banner:
                            logger.info(f"{TAG} Service seems to be: {Fore.LIGHTYELLOW_EX}{service}{Fore.RESET}")
                        return service
    except Exception as ex:
        logger.error(f"{TAG} Failed to grab banner: {ex}")

    return None


def indentify_http_service(host: str, port: int) -> bool:
    client = httpclient.HTTPClient()
    logger.getLogger("tornado").disabled = True

    for prot in ["http", "https"]:
        try:
            if client.fetch(build_url(prot, host, port)):
                client.close()
                return True
        except:
            pass

    client.close()
    logger.getLogger("tornado").disabled = False
    return False
