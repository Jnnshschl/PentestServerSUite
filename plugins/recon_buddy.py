import asyncio
import ipaddress
import json
import logging as logger
import os
import re
import shlex
import shutil
import socket
import subprocess
import tempfile
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from urllib.parse import parse_qs, unquote, urlencode, urljoin, urlparse, urlunparse
from urllib.request import urlretrieve
from uuid import uuid4

import nmap
from certipy.commands.find import Find
from certipy.lib.target import Target
from colorama import Fore
from humanize import naturalsize
from impacket.smbconnection import SessionError, SMBConnection
from ldap3 import ALL, SUBTREE, Connection, Server
from python_hosts import Hosts, HostsEntry
from tornado import gen, httpclient, ioloop
from tqdm import tqdm
from xxhash import xxh64_intdigest

from pssutil.cmdutils import CmdLenValidator
from pssutil.common import get_http_status_code_color
from pssutil.fileutils import execute_and_read_file_lines

TAG = f"[{Fore.LIGHTYELLOW_EX}ReconBuddy{Fore.RESET}]"

WHATWEB_PLUGIN_BLACKLIST = ["Country", "IP"]

WORDLISTS_FOLDER = Path("./wordlists")
WORDLISTS = {
    "vhosts": "https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/DNS/subdomains-top1million-5000.txt",
    "lfi": "https://raw.githubusercontent.com/carlospolop/Auto_Wordlists/main/wordlists/file_inclusion_linux.txt",
}

HOSTNAME_REGEX = re.compile(r"^(([a-zA-Z0-9]|[a-zA-Z0-9][a-zA-Z0-9\-]*[a-zA-Z0-9])\.)*([A-Za-z0-9]|[A-Za-z0-9][A-Za-z0-9\-]*[A-Za-z0-9])$")

IDISC_REGEXES = [
    re.compile(
        r"(.*\.(ai|asc|asp|aspx|awk|bat|c|cgi|class|cpp|cs|css|csv|dart|db|dbf|der|dll|doc|docx|ejs|elf|eps|erb|exe|gdb|gif|go|gpg|gz|h|hpp|htm|html|ini|ipynb|jar|java|jsp|js|json|jsx|key|kdbx|log|lua|mdb|md|mdb|mp3|mp4|msg|nef|o|odp|ods|odt|ogg|orf|ova|ovf|p12|pas|pb|pdf|pem|php|pl|png|ppt|pptx|ps1|psd|py|rb|reg|rpm|rs|rtf|sdf|sh|sln|sql|sqlitedb|sr2|svg|swift|tar|tif|tiff|ts|tsv|txt|vbs|vdi|vhd|vmem|vmsd|vmsn|vmss|vmtm|yml|xml).*)"
    ),
]

BANNER_REGEXES = {
    "HTTP": [
        re.compile(r"^HTTP\/.+\ [0-9]{1,3}\ "),
    ],
    "SSH": [
        re.compile(r"^SSH-[0-9]\.[0-9]-.+"),
    ],
}


def add_cmd(pm, cmd):
    rbuddy_handler = cmd.add(["rbuddy", "reconbuddy"])
    rbuddy_handler.add(["scan"], CmdLenValidator(init_recon_scan, 1, ["hostname or ipadress"]))
    rbuddy_handler.add(["vhosts"], CmdLenValidator(init_http_vhost_scan, 1, ["hostname or ipadress"]))
    rbuddy_handler.add(["bannergrab"], CmdLenValidator(init_banner_grab, 2, ["hostname or ipadress", "port"]))
    rbuddy_handler.add(["identifyservice"], CmdLenValidator(init_service_identify, 2, ["hostname or ipadress", "port"]))
    rbuddy_handler.add(["http"], CmdLenValidator(init_http_recon_scan, 1, ["hostname or ipadress"]))
    rbuddy_handler.add(["adcs"], CmdLenValidator(init_adcs_recon_scan, 1, ["hostname or ipadress"]))
    rbuddy_handler.add(["ldap"], CmdLenValidator(init_ldap_recon_scan, 1, ["hostname or ipadress"]))
    rbuddy_handler.add(["snmp"], CmdLenValidator(init_snmp_recon_scan, 1, ["hostname or ipadress"]))
    rbuddy_handler.add(["smb"], CmdLenValidator(init_smb_recon_scan, 1, ["hostname or ipadress"]))

    lfi_handler = rbuddy_handler.add(["wordlists"])
    lfi_handler.add(["update"], update_wordlists)

    lfi_handler = rbuddy_handler.add(["lfi"])
    lfi_handler.add(["scan"], CmdLenValidator(init_http_lfi_scan, 1, ["url with parameters"]))


def update_wordlists(args):
    for filename, url in WORDLISTS.items():
        download_wordlist(url, Path(WORDLISTS_FOLDER, filename))


def download_wordlist(url, path):
    try:
        if not WORDLISTS_FOLDER.exists():
            os.makedirs(WORDLISTS_FOLDER)

        logger.info(f'{TAG} Downloading "{Fore.LIGHTCYAN_EX}{path}{Fore.RESET}": {Fore.LIGHTCYAN_EX}{url}{Fore.RESET}')

        if path.exists():
            os.remove(path)

        urlretrieve(url, path)
    except Exception as ex:
        logger.error(f'{TAG} Failed to download wordlist "{Fore.LIGHTCYAN_EX}{path}{Fore.RESET}": {ex}')


def get_wordlist(name):
    try:
        if name in WORDLISTS:
            path = Path(WORDLISTS_FOLDER, name)

            if not path.exists():
                download_wordlist(WORDLISTS[name], path)

            with open(path) as wl:
                return [x.strip() for x in wl.readlines()]
    except Exception as ex:
        logger.error(f'{TAG} Failed to read wordlist "{Fore.LIGHTCYAN_EX}{path}{Fore.RESET}": {ex}')
    return []


def generate_wordlist_cewl(url):
    try:
        return execute_and_read_file_lines(f"cewl --convert-umlauts -w '{{FILE}}' {url}")
    except Exception as ex:
        logger.error(f'{TAG} Failed to generate wordlist with cewl for "{Fore.LIGHTCYAN_EX}{url}{Fore.RESET}": {ex}')
    return []


def generate_wordlist_cewler(url):
    try:
        return execute_and_read_file_lines(
            f"cewler --min-word-length 3 -s children --include-js --include-css --include-pdf --output '{{FILE}}' {url}"
        )
    except Exception as ex:
        logger.error(f'{TAG} Failed to generate wordlist with cewler for "{Fore.LIGHTCYAN_EX}{url}{Fore.RESET}": {ex}')
    return []


def init_recon_scan(args):
    try:
        host = args[0]
        nmap_scanner = nmap.PortScanner()

        min_rate = int(args[1]) if len(args) > 1 else 100
        services = {}

        def identified_service(services, service, port, print_msg: bool = False):
            if service not in services:
                services[service] = []

            if port not in services[service]:
                services[service].append(port)

            if print_msg:
                logger.info(f"{TAG} >> {Fore.LIGHTGREEN_EX}Service identified as{Fore.RESET}: {Fore.YELLOW}{service}{Fore.RESET}")

        logger.info(f"{TAG} Scanning TCP: {host}")
        nmap_tcp_scan = nmap_scanner.scan(host, arguments=f"-Pn -sV --min-rate {min(6000, min_rate)} -p-")

        if "scan" in nmap_tcp_scan and host in nmap_tcp_scan["scan"]:
            if "tcp" in nmap_tcp_scan["scan"][host] and nmap_tcp_scan["scan"][host]["tcp"]:
                for port, data in nmap_tcp_scan["scan"][host]["tcp"].items():
                    service_name = f'{data.get("product", "n/a")} {data.get("version", "n/a")}'
                    logger.info(
                        f'{TAG} TCP {Fore.LIGHTCYAN_EX}{str(port).ljust(5)}{Fore.RESET} : {data.get("state", "unknown")} [{Fore.YELLOW}{data.get("name", "NONE").upper()}{Fore.RESET}] ({Fore.YELLOW}{service_name}{Fore.RESET})'
                    )

                    if "name" in data and data["name"] and data["name"].lower() != "unknown":
                        if "version" in data and data["version"]:
                            run_exploitdb_lookup(service_name)

                        identified_service(services, data["name"], port)
                    else:
                        service = try_identify_service_tcp(host, port)

                        if service:
                            identified_service(services, service, port, True)
            else:
                logger.warn(f"{TAG} No open TCP ports found...")
        else:
            logger.error(f"{TAG} Failed to run nmap TCP scan...")

        logger.info(f"{TAG} Scanning UDP: {host}")
        nmap_udp_scan = nmap_scanner.scan(host, arguments=f"-Pn -sU --min-rate {min(2000, min_rate)}")

        if "scan" in nmap_udp_scan and host in nmap_udp_scan["scan"]:
            if "udp" in nmap_udp_scan["scan"][host] and nmap_udp_scan["scan"][host]["udp"]:
                for port, data in nmap_udp_scan["scan"][host]["udp"].items():
                    if data.get("state", "unknown") != "closed":
                        service_name = f'{data.get("product", "n/a")} {data.get("version", "n/a")}'
                        logger.info(
                            f'{TAG} UDP {Fore.LIGHTCYAN_EX}{str(port).ljust(5)}{Fore.RESET} : {data.get("state", "unknown")} [{Fore.YELLOW}{data.get("name", "NONE").upper()}{Fore.RESET}] ({Fore.YELLOW}{service_name}{Fore.RESET})'
                        )

                        if "name" in data and data["name"] and data["name"].lower() != "unknown":
                            if "version" in data and data["version"]:
                                run_exploitdb_lookup(service_name)

                            identified_service(services, data["name"], port)
                        else:
                            service = try_identify_service_udp(host, port)

                            if service:
                                identified_service(services, service, port, True)
            else:
                logger.warn(f"{TAG} No open UDP ports found...")
        else:
            logger.error(f"{TAG} Failed to run nmap UDP scan...")

        for service, ports in services.items():
            service = service.upper()

            if service == "HTTP":
                [http_recon(host, port) for port in ports]
            elif service == "SNMP":
                [snmp_recon(host, port) for port in ports]
            elif service == "MICROSOFT-DS":
                [smb_recon(host, port) for port in ports]
            elif service == "LDAP":
                [ldap_recon(host, port) for port in ports]

    except Exception as ex:
        logger.error(f"{TAG} Failed to run recon scan: {ex}")


def init_http_recon_scan(args):
    try:
        if len(args > 1):
            http_recon(args[0], int(args[1]))
        else:
            http_recon(args[0], 80 if args[0].startswith("http:") else 443)
    except Exception as ex:
        logger.error(f"{TAG} Failed to run HTTP recon: {ex}")


def init_adcs_recon_scan(args):
    try:
        adcs_recon(args[0], args[1], args[2], args[3])
    except Exception as ex:
        logger.error(f"{TAG} Failed to run AD-CS recon: {ex}")


def init_ldap_recon_scan(args):
    try:
        ldap_recon(
            args[0],
            int(args[1]) if len(args) > 1 else 389,
            domain=args[2] if len(args) > 2 else None,
            user=args[3] if len(args) > 3 else None,
            password=args[4] if len(args) > 4 else None,
        )
    except Exception as ex:
        logger.error(f"{TAG} Failed to run LDAP recon: {ex}")


def init_snmp_recon_scan(args):
    try:
        snmp_recon(args[0], int(args[1]) if len(args) > 1 else 161)
    except Exception as ex:
        logger.error(f"{TAG} Failed to run SNMP recon: {ex}")


def init_smb_recon_scan(args):
    try:
        smb_recon(args[0], int(args[1]) if len(args) > 1 else 445, int(args[2]) if len(args) > 2 else 2)
    except Exception as ex:
        logger.error(f"{TAG} Failed to run SMB recon: {ex}")


def init_banner_grab(args):
    try:
        identify_by_banner_grabbing(args[0], int(args[1]), True)
    except Exception as ex:
        logger.error(f"{TAG} Failed to run banner grab: {ex}")


def init_service_identify(args):
    try:
        service = try_identify_service_tcp(args[0], int(args[1]))

        if service:
            logger.info(f"{TAG} >> {Fore.LIGHTGREEN_EX}Service identified as{Fore.RESET}: {Fore.YELLOW}{service}{Fore.RESET}")
        else:
            logger.info(f"{TAG} >> {Fore.LIGHTRED_EX}Service could not be identified{Fore.RESET}")
    except Exception as ex:
        logger.error(f"{TAG} Failed to identify service: {ex}")


def try_identify_service_tcp(host: str, port: int, print_banner: bool = False):
    try:
        service = identify_by_banner_grabbing(host, port, print_banner)

        if service:
            return service
        else:
            indentifiers = {"HTTP": [indentify_http_service]}

            for service, identifier_fns in indentifiers.items():
                for identifier_fn in identifier_fns:
                    if identifier_fn(host, port):
                        return service
    except Exception as ex:
        logger.error(f"{TAG} Failed to identify service: {ex}")

    return None


def try_identify_service_udp(host: str, port: int, print_banner: bool = False):
    try:
        pass
    except Exception as ex:
        logger.error(f"{TAG} Failed to identify service: {ex}")

    return None


def build_url(scheme, host, port):
    return f"{scheme}://{host}:{port}"


def run_cmd(cmd):
    return subprocess.run(shlex.split(cmd), capture_output=True).stdout


def run_exploitdb_lookup(service_name):
    try:
        searchsploit_result = json.loads(run_cmd(f"searchsploit -w --json '{service_name}'"))

        if "RESULTS_EXPLOIT" in searchsploit_result and searchsploit_result["RESULTS_EXPLOIT"]:
            result_str = f"{Fore.RESET}\n".join(
                [f"{Fore.LIGHTYELLOW_EX}{x['Title']}{Fore.RESET}: {x['URL']}" for x in searchsploit_result["RESULTS_EXPLOIT"]]
            )
            result_str = re.sub("- ", f"{Fore.RESET} - {Fore.LIGHTRED_EX}", result_str)
            logger.info(f"{TAG} >> {Fore.LIGHTGREEN_EX}Exploits available{Fore.RESET}:\n{result_str}")
        else:
            # logger.info(f"{TAG} >> {Fore.WHITE}No exploits found...{Fore.RESET}")
            pass
    except Exception as ex:
        logger.error(f"{TAG} Failed to search for exploits: {ex}")


def run_whatweb(url):
    _, path = tempfile.mkstemp(suffix=".json")

    try:
        run_cmd(f"whatweb -q --log-json '{path}' '{url}'")

        with open(path) as tmp_file:
            whatweb_results = json.loads(tmp_file.read())

            for whatweb_result in whatweb_results:
                if "target" in whatweb_result and "plugins" in whatweb_result:
                    whatweb_plugin_results = []

                    for x, y in whatweb_result["plugins"].items():
                        if x not in WHATWEB_PLUGIN_BLACKLIST and y:
                            whatweb_plugin_results.append(f"{Fore.LIGHTYELLOW_EX}{x}{Fore.RESET}: {y}")

                    result_str = "\n".join(whatweb_plugin_results)
                    logger.info(f"{TAG} >> whatweb results for \"{whatweb_result['target']}\":\n{result_str}")
    finally:
        os.remove(path)


def add_host_entry(hosts, ip, hostname):
    entry_type = "ipv4" if isinstance(ip, ipaddress.IPv4Address) else "ipv6"
    existing_hosts = hosts.find_all_matching(address=str(ip))

    if len(existing_hosts) > 0:
        for entry in existing_hosts:
            if hostname in entry.names:
                return

    hosts.add([HostsEntry(entry_type=entry_type, address=str(ip), names=[hostname])], merge_names=True)
    hosts.write()
    logger.info(f'{TAG} Created hostentry: "{Fore.YELLOW}{hostname}{Fore.RESET}" -> "{Fore.YELLOW}{ip}{Fore.RESET}"')


def http_handle_unknown_host(url, redirect):
    try:
        parsed_url = urlparse(url)

        if HOSTNAME_REGEX.match(redirect):
            scheme = parsed_url.scheme or "http"
            redirect = f"{scheme}://{redirect}"

        parsed_redirect = urlparse(redirect)

        if parsed_url.hostname == parsed_redirect.hostname:
            # only http changed to https or location changed, not relevant for us
            return

        # check wheter a host can be resolved, if not, add it to the hosts file
        try:
            socket.getaddrinfo(parsed_redirect.hostname)
            # we can resolve it, no need to add host entry
            return
        except:
            hosts = Hosts()

            try:
                # url is a ip
                ip = ipaddress.ip_address(parsed_url.hostname)
                add_host_entry(hosts, ip, parsed_redirect.hostname)
                return
            except:
                # url seems to be a hostname, try to resolve the ip and add it to the hosts file
                for host_entry in hosts.find_all_matching(name=parsed_url.hostname):
                    try:
                        add_host_entry(hosts, ipaddress.ip_address(host_entry.address), parsed_redirect.hostname)
                        return
                    except:
                        pass

                logger.error(f"{TAG} Failed to auto create hostentry")

    except:
        pass


def http_follow_redirects(url) -> str:
    resp = None

    try:
        resp = httpclient.HTTPClient().fetch(url, follow_redirects=False, validate_cert=False, raise_error=False)

        # only hanlde permanent redirects
        if resp.code in [301, 302, 307, 308]:
            redirect_loc = resp.headers.get("Location", None) or resp.headers.get("location", None)

            if redirect_loc:
                if not redirect_loc.startswith("http"):
                    redirect_loc = urljoin(url, redirect_loc)

                logger.info(f'{TAG} Redirect detected: "{Fore.YELLOW}{url}{Fore.RESET}" -> "{Fore.YELLOW}{redirect_loc}{Fore.RESET}"')
                http_handle_unknown_host(url, redirect_loc)
                url = http_follow_redirects(redirect_loc)
    except Exception as ex:
        logger.error(f"{TAG} Failed to follow redirect: {ex}")

    return url


def http_send_get(urls, description):
    http_client = httpclient.AsyncHTTPClient()
    reqs = [
        http_client.fetch(
            url,
            method="GET",
            request_timeout=0,
            validate_cert=False,
            raise_error=False,
            follow_redirects=False,
        )
        for url in urls
    ]
    return http_send_requests(reqs, description)


def http_send_requests(reqs, description):
    @gen.coroutine
    def fetch_and_handle():
        results = []
        waiter = gen.WaitIterator(*reqs)

        with tqdm(
            ascii=True,
            desc=description,
            unit=f" {Fore.YELLOW}requests{Fore.RESET}",
            total=len(reqs),
        ) as pbar:
            while not waiter.done():
                try:
                    response = yield waiter.next()
                except:
                    pass
                else:
                    results.append(response)

                pbar.update()

        return results

    return ioloop.IOLoop.current().run_sync(fetch_and_handle)


def http_discover_hvosts(url, wordlist):
    target = urlparse(url)

    rngstr = abs(hash(uuid4().hex)) % (10**16)
    rngurl = f"{rngstr}.{target.hostname}"
    logger.info(f'{TAG} Using random url as hopefully non-existing sample "{Fore.YELLOW}{rngurl}{Fore.RESET}"')

    initial_response = httpclient.HTTPClient().fetch(
        url, headers={"Host": rngurl}, method="GET", follow_redirects=False, validate_cert=False, raise_error=False
    )
    initial_response_hash = xxh64_intdigest(initial_response.body)

    http_client = httpclient.AsyncHTTPClient()
    reqs = [
        http_client.fetch(
            url,
            method="GET",
            headers={"Host": f"{u}.{target.hostname}"},
            request_timeout=0,
            connect_timeout=0,
            validate_cert=False,
            raise_error=False,
            follow_redirects=False,
        )
        for u in wordlist
    ]

    possible_vhosts = http_send_requests(reqs, f"{Fore.YELLOW}Scanning vHosts{Fore.RESET}")
    valid_status_codes = list(range(200, 299)) + [301, 302, 307, 401, 403, 405, 500]

    def filter_respone(response):
        try:
            if response.code in valid_status_codes and xxh64_intdigest(response.body) != initial_response_hash:
                return (response.request.headers.get("Host", None) or response.request.headers.get("host", None), response.code)
        except:
            pass
        return (None, 0)

    vhosts = {}

    with ThreadPoolExecutor() as pool:
        for vs in pool.map(filter_respone, possible_vhosts):
            if vs[0]:
                vhosts[vs[0]] = vs[1]

    return vhosts


def http_recon(host, port, https: bool = False):
    try:
        url = build_url("https" if https else "http", host, port)
        url = http_follow_redirects(url)
        parsed_url = urlparse(url)

        try:
            run_whatweb(url)
        except Exception as ex_whatweb:
            logger.error(f"{TAG} Failed to run whatweb: {ex_whatweb}")

        try:
            ipaddress.ip_address(parsed_url.hostname)
        except:
            # scan vhosts if url is a hostname
            vhosts = init_http_vhost_scan([url])

            if vhosts:
                for vhost, status_code in vhosts:
                    http_handle_unknown_host(url, vhost)
                    http_recon(vhost, port)
    except Exception as ex:
        logger.error(f"{TAG} Failed to run HTTP recon: {ex}")


def adcs_recon(host, domain, user, password):
    target = Target.create(target_ip=host, dc_ip=host, domain=domain, username=user, password=password)
    find = Find(target, vulnerable=True, stdout=True)
    find.find()


def snmp_recon(host, port):
    try:
        if shutil.which("snmpbulkwalk"):
            logger.info(f"{TAG} Walking SNMP using snmpbulkwalk...")
            snmp_lines = execute_and_read_file_lines(f"snmpbulkwalk {host} -v 2c -c public > {{FILE}}", True)

            for regex in IDISC_REGEXES:
                for match in regex.findall(snmp_lines):
                    print(match[0])
        else:
            logger.warn(f"{TAG} Unable to walk SNMP: snmpbulkwalk not installed...")
    except Exception as ex:
        logger.error(f"{TAG} Failed to run SNMP recon: {ex}")


def smb_recon(host, port, max_depth=2, silent=False, user="guest", password=""):
    try:
        logger.info(f"{TAG} Running SMB recon:")
        conn = SMBConnection(host, host, None, port, 5)
        conn.login(user, password)

        for share in sorted(conn.listShares(), key=lambda x: x["shi1_type"], reverse=True):
            share_name = share["shi1_netname"][:-1]
            share_type = share["shi1_type"]
            print(f"[{share_type:10}] {Fore.LIGHTYELLOW_EX}{share_name}{Fore.RESET} \"{share['shi1_remark'][:-1]}\"", end="")

            if share_type == 0:
                try:

                    def list_share(sname, path, print_status=False, max_depth=2, depth=0):
                        if depth < max_depth:
                            try:
                                files = conn.listPath(sname, f"{path}*")

                                if print_status:
                                    print(f": {Fore.LIGHTGREEN_EX}STATUS_SUCCESS{Fore.RESET}")

                                for file_info in files:
                                    filename = file_info.get_longname()

                                    if filename not in [".", ".."]:
                                        if file_info.is_directory():
                                            appendix = f"{Fore.WHITE}/{Fore.RESET}"
                                        else:
                                            appendix = f" ({naturalsize(file_info.get_filesize())})"

                                        for regex in IDISC_REGEXES:
                                            if regex.match(filename):
                                                file_color = Fore.LIGHTGREEN_EX
                                                break
                                        else:
                                            file_color = Fore.WHITE

                                        print(f"{depth * '  '}{file_color}{filename}{Fore.RESET}{appendix}")

                                        if file_info.is_directory():
                                            list_share(share_name, f"{path}{file_info.get_longname()}/", False, max_depth, depth + 1)
                            except SessionError as se:
                                print(f"{Fore.LIGHTRED_EX}{se.getErrorString()[0]}{Fore.RESET}")

                    tree_id = conn.connectTree(share_name)
                    list_share(share_name, "", True, max_depth)
                    conn.disconnectTree(tree_id)
                except SessionError as se:
                    print(f": {Fore.LIGHTRED_EX}{se.getErrorString()[0]}{Fore.RESET}")
            else:
                print()

    except SessionError as se:
        print(f"Failed to run SMB recon: {Fore.LIGHTRED_EX}{se.getErrorString()[0]}{Fore.RESET}")
    except Exception as ex:
        if not silent:
            logger.error(f"{TAG} Failed to run SMB recon: {ex}")


def ldap_recon(host, port, protocol="ldap", silent=False, domain=None, user=None, password=None):
    try:
        logger.info(f"{TAG} Running LDAP recon:")
        server = Server(f"{protocol}://{host}", port, get_info=ALL)

        if not user or not password:
            conn = Connection(server, auto_bind=True)
        else:
            conn = Connection(server, user=user, password=password, auto_bind=True)

        conn.bind()
        try:
            base_dn = server.info.other["defaultNamingContext"][0]
        except:
            try:
                base_dn = server.info.other["rootDomainNamingContext"][0]
            except:
                try:
                    base_dn = server.info.naming_contexts[0]
                except:
                    logger.error(f"{TAG} Unable to find base DN for LDAP server...")
                    return

        conn.search(search_base=base_dn, search_filter="(objectClass=*)", search_scope=SUBTREE, attributes="*")

        possible_users = []
        interesting_descriptions = {}

        for entry in conn.entries:
            print(f"[{Fore.LIGHTYELLOW_EX}{entry.entry_dn}{Fore.RESET}]")

            if "OU=" in entry.entry_dn or ("objectClass" in entry.entry_attributes and "user" in entry["objectClass"]):
                try:
                    if "sAMAccountName" in entry.entry_attributes:
                        possible_users.append(entry["sAMAccountName"])
                    else:
                        possible_users.append(entry.entry_dn.split("CN=")[1].split(",")[0])
                except:
                    pass

            for attribute in entry.entry_attributes:
                attr = str(entry[attribute])
                color = Fore.WHITE

                if "password" in attr.lower() and "rodc password" not in attr.lower() and "rodc password" not in entry.entry_dn.lower():
                    color = Fore.LIGHTGREEN_EX

                    if entry.entry_dn not in interesting_descriptions:
                        interesting_descriptions[entry.entry_dn] = []

                    interesting_descriptions[entry.entry_dn].append(f"{attribute}: {attr}")

                print(f"{attribute}: {color}{attr}{Fore.RESET}")

            print()

        logger.info(f'{TAG} Server base DN: "{Fore.LIGHTYELLOW_EX}{base_dn}{Fore.RESET}"')

        if possible_users:
            logger.info(f"{TAG} Possible usernames:")

            for user in possible_users:
                print(str(user))

            print()

        if interesting_descriptions:
            logger.info(f"{TAG} Attributes with interesting stuff:")

            for dn, attributes in interesting_descriptions.items():
                print(f"[{Fore.LIGHTYELLOW_EX}{dn}{Fore.RESET}]")

                for attribute in attributes:
                    print(attribute)

                print()
    except Exception as ex:
        logger.error(f"{TAG} Failed to run LDAP recon: {ex}")


def init_http_vhost_scan(args):
    try:
        url = http_follow_redirects(args[0])

        if shutil.which("cewl"):
            wl_cewl = generate_wordlist_cewl(url)

        if shutil.which("cewler"):
            wl_cewler = generate_wordlist_cewler(url)

        vhosts = http_discover_hvosts(url, set(get_wordlist("vhosts") + wl_cewl + wl_cewler))
        vhosts = sorted(vhosts.items(), key=lambda x: (-x[1], x[0]))

        for vhost, status_code in vhosts:
            logger.info(
                f"{TAG} Discovered vHost: {Fore.YELLOW}{vhost}{Fore.RESET} => {get_http_status_code_color(status_code)}{status_code}{Fore.RESET}"
            )

        return vhosts
    except Exception as ex:
        logger.error(f"{TAG} Failed to run vHost scan: {ex}")


def init_http_lfi_scan(args):
    url = list(urlparse(args[0]))
    parameters = parse_qs(url[4])
    lfi_parameters = list(filter(None, [x if "LFI" in y else None for x, y in parameters.items()]))

    lfi_urls = {}
    lfi_count = 0

    for lfi in get_wordlist("lfi"):
        try:
            filename = Path(unquote(lfi)).name

            if filename not in lfi_urls:
                lfi_urls[filename] = []

            for lfi_param in lfi_parameters:
                url_copy = url.copy()
                new_parameters = parameters.copy()
                new_parameters[lfi_param] = re.sub("LFI", lfi, new_parameters[lfi_param][0])
                url_copy[4] = urlencode(new_parameters)
                lfi_urls[filename].append(urlunparse(url_copy))
                lfi_count += 1
        except Exception as ex:
            logger.error(f'{TAG} Invalid LFI path "{lfi}": {ex}')

    lfi_responses = {}

    async def scan_url_lfi(file, urls, pbar):
        http_client = httpclient.AsyncHTTPClient()
        valid_status_codes = list(range(200, 299)) + [301, 302, 307]

        async def fetch_website(http_client, u):
            try:
                response = await http_client.fetch(u, method="GET", follow_redirects=False, validate_cert=False, raise_error=False)

                if response.code in valid_status_codes:
                    lfi_responses[file] = response.body.decode()
                    return True
            except:
                return False

        for u in urls:
            if await fetch_website(http_client, u):
                break

        pbar.update()

    with tqdm(
        ascii=True,
        desc="Scanning LFI's",
        unit=f" {Fore.YELLOW}requests{Fore.RESET}",
        total=len(lfi_urls),
    ) as pbar:

        async def scan_url_lfis(futures):
            return await asyncio.gather(*futures)

        asyncio.run(scan_url_lfis([scan_url_lfi(file, urls, pbar) for file, urls in lfi_urls.items()]))

    for file, content in lfi_responses.items():
        logger.info(f'{TAG} LFI "{file}":\n{content}')


def identify_by_banner_grabbing(host: str, port: int, print_banner: bool = False):
    try:
        sock = socket.socket()
        sock.settimeout(4)
        sock.connect((host, port))
        sock.send("\r\n\0".encode("ASCII"))
        banner_bytes = sock.recv(1024)
        sock.close()

        banner = banner_bytes.decode(errors="ignore").strip()

        if banner:
            if print_banner:
                logger.info(f"{TAG} Grabbed banner:\n{Fore.LIGHTWHITE_EX}{banner}{Fore.RESET}")

            for service, regexes in BANNER_REGEXES.items():
                for rgx in regexes:
                    if rgx.match(banner):
                        if print_banner:
                            logger.info(f"{TAG} Service seems to be: {Fore.LIGHTYELLOW_EX}{service}{Fore.RESET}")
                        return service
    except Exception as ex:
        logger.error(f"{TAG} Failed to grab banner: {ex}")

    return None


def indentify_http_service(host: str, port: int) -> bool:
    client = httpclient.HTTPClient()
    logger.getLogger("tornado").disabled = True

    for prot in ["http", "https"]:
        try:
            if client.fetch(build_url(prot, host, port)):
                client.close()
                return True
        except:
            pass

    client.close()
    logger.getLogger("tornado").disabled = False
    return False
